{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490916d3",
   "metadata": {},
   "source": [
    "# ИУ5-25М Рыжкова Юлия Николаевна \n",
    "# РК №2\n",
    "\n",
    "## CountVectorizer (SVC) и TfidfVectorizer (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee26d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458e7dd",
   "metadata": {},
   "source": [
    "Выбран набор данных IMDB, содержащий 50 000 рецензий на фильмы, предназначен для обработки естественного языка (NLP) или анализа текста.\n",
    "\n",
    "Это набор данных для бинарной классификации тональности, который содержит значительно больше данных, чем предыдущие эталонные наборы. Он включает в себя 25 000 ярко выраженных (полярных) отзывов на фильмы для обучения и 25 000 — для тестирования.\n",
    "\n",
    "Задача: предсказать количество положительных и отрицательных отзывов, используя алгоритмы классификации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e12aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'IMDB_Dataset.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746e4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6d6c8",
   "metadata": {},
   "source": [
    "## Способ 1. Классификация на основе CountVectorizer (SVC)\n",
    "\n",
    "CountVectorizer: Преобразует текст в матрицу частот слов. Простая \"bag of words\" модель: каждое слово — признак, значение — количество раз, когда оно встречается.\n",
    "\n",
    "SVC (Support Vector Classifier): Ищет \"гиперплоскость\", которая максимально разделяет классы. Особенно эффективен при большом количестве признаков (что типично для текстов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1540d0fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m y_pred_svc \u001b[38;5;241m=\u001b[39m svc_model\u001b[38;5;241m.\u001b[39mpredict(X_test_count)\n\u001b[1;32m     12\u001b[0m target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y_test)]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39mtarget_names))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Векторизация текста\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Обучение классификатора\n",
    "svc_model = LinearSVC()\n",
    "svc_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Оценка модели\n",
    "y_pred_svc = svc_model.predict(X_test_count)\n",
    "target_names = [str(cls) for cls in np.unique(y_test)]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec17f83",
   "metadata": {},
   "source": [
    "## Способ 2. Классификация на основе TfidfVectorizer (LogisticRegression)\n",
    "\n",
    "TfidfVectorizer: Учитывает не только частоту слова, но и то, насколько оно уникально в других документах (TF-IDF: term frequency × inverse document frequency). Придаёт больший вес значимым словам и уменьшает влияние часто встречающихся (например, “the”, “a”).\n",
    "\n",
    "Logistic Regression: Простая, быстрая линейная модель, предсказывает вероятность принадлежности к классу. Хорошо работает при разреженных признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b905d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация текста\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Обучение классификатора\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Оценка модели\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3213ac",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Оба метода показывают хорошие результаты на задаче бинарной классификации текста.\n",
    "Модель с TfidfVectorizer + LogisticRegression показала качество немного выше за счёт более тонкого подхода к весам слов.\n",
    "Метод с CountVectorizer + SVC также эффективен, особенно при более простом словаре. Выбор зависит от задачи и требований к скорости и интерпретируемости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5e5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
